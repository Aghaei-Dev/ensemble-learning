{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hybrid Ensemble Learning: Classification and Clustering\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This project implements a **hybrid (ensemble) classifier** based on the aggregation of both supervised and unsupervised learning methods.\n",
        "\n",
        "### Ensemble Classification Methods:\n",
        "- **MLP Neural Network** - Multi-layer Perceptron\n",
        "- **RBF Neural Network** - Radial Basis Function Network\n",
        "- **k-NN Algorithm** - k-Nearest Neighbors\n",
        "- **GP Algorithm** - Gaussian Process Classifier\n",
        "- **Naïve Bayes Algorithm** - Gaussian Naive Bayes\n",
        "\n",
        "### Ensemble Clustering Methods:\n",
        "- **k-Means Algorithm**\n",
        "- **k-Medoids Algorithm**\n",
        "- **DIANA Algorithm** - Divisive Analysis\n",
        "\n",
        "### Datasets:\n",
        "- **RCV1 (Reuters)** - Text classification dataset\n",
        "- **Forest Covtype** - Forest cover type prediction dataset\n",
        "\n",
        "### Evaluation Metrics:\n",
        "- **Classification**: Accuracy, Precision, Sensitivity (Recall)\n",
        "- **Clustering**: Rand Index, F-measure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 1: Installing and Importing Required Libraries\n",
        "\n",
        "First, we need to install all necessary libraries for machine learning, clustering, and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /home/hasan/anaconda3/lib/python3.13/site-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /home/hasan/anaconda3/lib/python3.13/site-packages (2.1.3)\n",
            "Requirement already satisfied: pandas in /home/hasan/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /home/hasan/anaconda3/lib/python3.13/site-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /home/hasan/anaconda3/lib/python3.13/site-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn-extra in /home/hasan/anaconda3/lib/python3.13/site-packages (0.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /home/hasan/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/hasan/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/hasan/anaconda3/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hasan/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/hasan/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/hasan/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/hasan/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/hasan/anaconda3/lib/python3.13/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/hasan/anaconda3/lib/python3.13/site-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/hasan/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/hasan/anaconda3/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /home/hasan/anaconda3/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/hasan/anaconda3/lib/python3.13/site-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/hasan/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "# Uncomment and run if packages are not installed\n",
        "!pip install scikit-learn numpy pandas matplotlib seaborn scikit-learn-extra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Core Libraries\n",
        "\n",
        "We import NumPy for numerical operations, Pandas for data manipulation, and Matplotlib/Seaborn for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Core libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Core libraries for data manipulation and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure matplotlib for better plots\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "print(\"✓ Core libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Machine Learning Libraries\n",
        "\n",
        "We import all the classifiers, clustering algorithms, and evaluation metrics from scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Machine learning libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Data preprocessing and model selection\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import TruncatedSVD, PCA\n",
        "\n",
        "# Classification metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, \n",
        "    precision_score, \n",
        "    recall_score,\n",
        "    confusion_matrix, \n",
        "    classification_report,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# Clustering metrics\n",
        "from sklearn.metrics import (\n",
        "    adjusted_rand_score,\n",
        "    silhouette_score,\n",
        "    normalized_mutual_info_score\n",
        ")\n",
        "from sklearn.metrics.cluster import contingency_matrix\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF as RBF_Kernel, ConstantKernel\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Clustering algorithms\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "\n",
        "# Ensemble methods\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "print(\"✓ Machine learning libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 2: Loading and Preparing Datasets\n",
        "\n",
        "We use two real-world datasets from scikit-learn:\n",
        "\n",
        "1. **Forest Covtype**: Contains cartographic variables to predict forest cover type. It has 54 features and 7 classes.\n",
        "\n",
        "2. **RCV1 (Reuters)**: A text classification dataset with news articles. It's a multi-label, sparse dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Load Forest Covtype Dataset\n",
        "\n",
        "The Forest Covertype dataset contains 581,012 samples with 54 features. Due to computational constraints, we sample a subset for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Forest Covtype dataset...\n"
          ]
        },
        {
          "ename": "HTTPError",
          "evalue": "HTTP Error 403: Forbidden",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fetch_covtype\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Forest Covtype dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m covtype \u001b[38;5;241m=\u001b[39m fetch_covtype()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Display dataset information\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDataset Description:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/sklearn/datasets/_covtype.py:200\u001b[0m, in \u001b[0;36mfetch_covtype\u001b[0;34m(data_home, download_if_missing, random_state, shuffle, return_X_y, as_frame, n_retries, delay)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TemporaryDirectory(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mcovtype_dir) \u001b[38;5;28;01mas\u001b[39;00m temp_dir:\n\u001b[1;32m    199\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mARCHIVE\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 200\u001b[0m     archive_path \u001b[38;5;241m=\u001b[39m _fetch_remote(\n\u001b[1;32m    201\u001b[0m         ARCHIVE, dirname\u001b[38;5;241m=\u001b[39mtemp_dir, n_retries\u001b[38;5;241m=\u001b[39mn_retries, delay\u001b[38;5;241m=\u001b[39mdelay\n\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    203\u001b[0m     Xy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgenfromtxt(GzipFile(filename\u001b[38;5;241m=\u001b[39marchive_path), delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m     X \u001b[38;5;241m=\u001b[39m Xy[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/sklearn/datasets/_base.py:1513\u001b[0m, in \u001b[0;36m_fetch_remote\u001b[0;34m(remote, dirname, n_retries, delay)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1513\u001b[0m         urlretrieve(remote\u001b[38;5;241m.\u001b[39murl, temp_file_path)\n\u001b[1;32m   1514\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (URLError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:214\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(urlopen(url, data)) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    215\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:189\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, context)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:495\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    494\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 495\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:604\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 604\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:533\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    532\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:466\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    465\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 466\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:613\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "print(\"Loading Forest Covtype dataset...\")\n",
        "covtype = fetch_covtype()\n",
        "\n",
        "# Display dataset information\n",
        "print(f\"\\nDataset Description:\")\n",
        "print(f\"- Total samples: {covtype.data.shape[0]:,}\")\n",
        "print(f\"- Number of features: {covtype.data.shape[1]}\")\n",
        "print(f\"- Number of classes: {len(np.unique(covtype.target))}\")\n",
        "print(f\"- Class labels: {np.unique(covtype.target)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'covtype' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Sample a subset for faster computation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Using stratified sampling to maintain class distribution\u001b[39;00m\n\u001b[1;32m      3\u001b[0m COVTYPE_SAMPLE_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20000\u001b[39m\n\u001b[0;32m----> 5\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(covtype\u001b[38;5;241m.\u001b[39mdata), COVTYPE_SAMPLE_SIZE, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m X_covtype \u001b[38;5;241m=\u001b[39m covtype\u001b[38;5;241m.\u001b[39mdata[indices]\n\u001b[1;32m      7\u001b[0m y_covtype \u001b[38;5;241m=\u001b[39m covtype\u001b[38;5;241m.\u001b[39mtarget[indices]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'covtype' is not defined"
          ]
        }
      ],
      "source": [
        "# Sample a subset for faster computation\n",
        "# Using stratified sampling to maintain class distribution\n",
        "COVTYPE_SAMPLE_SIZE = 20000\n",
        "\n",
        "indices = np.random.choice(len(covtype.data), COVTYPE_SAMPLE_SIZE, replace=False)\n",
        "X_covtype = covtype.data[indices]\n",
        "y_covtype = covtype.target[indices]\n",
        "\n",
        "print(f\"Sampled dataset:\")\n",
        "print(f\"- Shape: {X_covtype.shape}\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "for cls, count in sorted(Counter(y_covtype).items()):\n",
        "    print(f\"  Class {cls}: {count} samples ({100*count/len(y_covtype):.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Load RCV1 (Reuters) Dataset\n",
        "\n",
        "RCV1 is a sparse text classification dataset. We'll reduce its dimensionality using TruncatedSVD for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading RCV1 (Reuters) dataset...\n",
            "(This may take a few minutes on first run)\n"
          ]
        },
        {
          "ename": "HTTPError",
          "evalue": "HTTP Error 403: Forbidden",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading RCV1 (Reuters) dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(This may take a few minutes on first run)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m rcv1 \u001b[38;5;241m=\u001b[39m fetch_rcv1()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDataset Description:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Total samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrcv1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/sklearn/datasets/_rcv1.py:212\u001b[0m, in \u001b[0;36mfetch_rcv1\u001b[0;34m(data_home, subset, download_if_missing, random_state, shuffle, return_X_y, n_retries, delay)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m each \u001b[38;5;129;01min\u001b[39;00m XY_METADATA:\n\u001b[1;32m    211\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m each\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m--> 212\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m _fetch_remote(\n\u001b[1;32m    213\u001b[0m         each, dirname\u001b[38;5;241m=\u001b[39mrcv1_dir, n_retries\u001b[38;5;241m=\u001b[39mn_retries, delay\u001b[38;5;241m=\u001b[39mdelay\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    215\u001b[0m     files\u001b[38;5;241m.\u001b[39mappend(GzipFile(filename\u001b[38;5;241m=\u001b[39mfile_path))\n\u001b[1;32m    217\u001b[0m Xy \u001b[38;5;241m=\u001b[39m load_svmlight_files(files, n_features\u001b[38;5;241m=\u001b[39mN_FEATURES)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/sklearn/datasets/_base.py:1513\u001b[0m, in \u001b[0;36m_fetch_remote\u001b[0;34m(remote, dirname, n_retries, delay)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1513\u001b[0m         urlretrieve(remote\u001b[38;5;241m.\u001b[39murl, temp_file_path)\n\u001b[1;32m   1514\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (URLError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:214\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(urlopen(url, data)) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    215\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:189\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, context)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:495\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    494\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 495\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:604\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 604\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:533\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    532\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:466\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    465\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 466\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.13/urllib/request.py:613\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_rcv1\n",
        "\n",
        "print(\"Loading RCV1 (Reuters) dataset...\")\n",
        "print(\"(This may take a few minutes on first run)\")\n",
        "\n",
        "rcv1 = fetch_rcv1()\n",
        "\n",
        "print(f\"\\nDataset Description:\")\n",
        "print(f\"- Total samples: {rcv1.data.shape[0]:,}\")\n",
        "print(f\"- Number of features: {rcv1.data.shape[1]:,}\")\n",
        "print(f\"- Number of target categories: {rcv1.target.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample and preprocess RCV1 data\n",
        "RCV1_SAMPLE_SIZE = 10000\n",
        "N_COMPONENTS = 100  # Reduced dimensions after SVD\n",
        "\n",
        "# Random sampling\n",
        "indices_rcv1 = np.random.choice(rcv1.data.shape[0], RCV1_SAMPLE_SIZE, replace=False)\n",
        "X_rcv1_sparse = rcv1.data[indices_rcv1]\n",
        "\n",
        "# Convert to dense array for processing\n",
        "X_rcv1 = X_rcv1_sparse.toarray()\n",
        "\n",
        "# For multi-label dataset, use the most frequent label for each sample\n",
        "y_rcv1 = np.array(rcv1.target[indices_rcv1].argmax(axis=1)).flatten()\n",
        "\n",
        "print(f\"Original sampled shape: {X_rcv1.shape}\")\n",
        "\n",
        "# Apply dimensionality reduction using TruncatedSVD\n",
        "print(f\"\\nApplying TruncatedSVD for dimensionality reduction...\")\n",
        "svd = TruncatedSVD(n_components=N_COMPONENTS, random_state=42)\n",
        "X_rcv1_reduced = svd.fit_transform(X_rcv1)\n",
        "\n",
        "print(f\"Reduced shape: {X_rcv1_reduced.shape}\")\n",
        "print(f\"Explained variance ratio: {svd.explained_variance_ratio_.sum():.4f}\")\n",
        "print(f\"Number of unique classes: {len(np.unique(y_rcv1))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Data Preparation Function\n",
        "\n",
        "This function handles:\n",
        "- Train/test splitting with stratification\n",
        "- Feature standardization (zero mean, unit variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data(X, y, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Prepare data for machine learning:\n",
        "    - Split into train/test sets with stratification\n",
        "    - Standardize features\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Feature matrix\n",
        "    y : array-like, shape (n_samples,)\n",
        "        Target labels\n",
        "    test_size : float\n",
        "        Proportion of data for testing\n",
        "    random_state : int\n",
        "        Random seed for reproducibility\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
        "    \"\"\"\n",
        "    # Split data with stratification to maintain class distribution\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, \n",
        "        test_size=test_size, \n",
        "        random_state=random_state, \n",
        "        stratify=y\n",
        "    )\n",
        "    \n",
        "    # Standardize features (important for neural networks and distance-based methods)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
        "\n",
        "print(\"✓ Data preparation function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare Forest Covtype data\n",
        "print(\"Preparing Forest Covtype data...\")\n",
        "X_train_cov, X_test_cov, y_train_cov, y_test_cov, scaler_cov = prepare_data(\n",
        "    X_covtype, y_covtype\n",
        ")\n",
        "print(f\"Training set size: {X_train_cov.shape[0]}\")\n",
        "print(f\"Test set size: {X_test_cov.shape[0]}\")\n",
        "\n",
        "# Prepare RCV1 data\n",
        "print(\"\\nPreparing RCV1 data...\")\n",
        "X_train_rcv, X_test_rcv, y_train_rcv, y_test_rcv, scaler_rcv = prepare_data(\n",
        "    X_rcv1_reduced, y_rcv1\n",
        ")\n",
        "print(f\"Training set size: {X_train_rcv.shape[0]}\")\n",
        "print(f\"Test set size: {X_test_rcv.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 3: Implementing Base Classifiers\n",
        "\n",
        "We implement five base classifiers with hyperparameter optimization:\n",
        "\n",
        "1. **MLP (Multi-Layer Perceptron)**: Deep neural network with backpropagation\n",
        "2. **RBF Network**: Uses radial basis function kernels\n",
        "3. **k-NN**: Instance-based learning using neighbor distances\n",
        "4. **Gaussian Process**: Probabilistic classifier using GP priors\n",
        "5. **Naive Bayes**: Probabilistic classifier assuming feature independence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Classifier Manager Class\n",
        "\n",
        "This class manages multiple classifiers, handles hyperparameter optimization, training, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ClassifierManager:\n",
        "    \"\"\"\n",
        "    A manager class for handling multiple classifiers with:\n",
        "    - Hyperparameter optimization using GridSearchCV\n",
        "    - Training and evaluation\n",
        "    - Results storage and comparison\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.classifiers = {}      # Stores classifier definitions\n",
        "        self.best_params = {}      # Stores optimal parameters\n",
        "        self.results = {}          # Stores evaluation results\n",
        "        self.cv_scores = {}        # Stores cross-validation scores\n",
        "    \n",
        "    def add_classifier(self, name, classifier, param_grid=None):\n",
        "        \"\"\"\n",
        "        Add a classifier to the manager.\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        name : str\n",
        "            Identifier for the classifier\n",
        "        classifier : estimator\n",
        "            Scikit-learn compatible classifier\n",
        "        param_grid : dict or None\n",
        "            Hyperparameter search space for GridSearchCV\n",
        "        \"\"\"\n",
        "        self.classifiers[name] = {\n",
        "            'model': classifier,\n",
        "            'param_grid': param_grid\n",
        "        }\n",
        "    \n",
        "    def optimize_and_train(self, X_train, y_train, cv=3, verbose=True):\n",
        "        \"\"\"\n",
        "        Optimize hyperparameters and train all classifiers.\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        X_train : array-like\n",
        "            Training features\n",
        "        y_train : array-like\n",
        "            Training labels\n",
        "        cv : int\n",
        "            Number of cross-validation folds\n",
        "        verbose : bool\n",
        "            Print progress information\n",
        "        \"\"\"\n",
        "        for name, clf_info in self.classifiers.items():\n",
        "            if verbose:\n",
        "                print(f\"\\n{'='*50}\")\n",
        "                print(f\"Training: {name}\")\n",
        "                print(f\"{'='*50}\")\n",
        "            \n",
        "            if clf_info['param_grid'] is not None:\n",
        "                # Perform grid search for hyperparameter optimization\n",
        "                grid_search = GridSearchCV(\n",
        "                    clf_info['model'],\n",
        "                    clf_info['param_grid'],\n",
        "                    cv=cv,\n",
        "                    scoring='accuracy',\n",
        "                    n_jobs=-1,\n",
        "                    return_train_score=True\n",
        "                )\n",
        "                grid_search.fit(X_train, y_train)\n",
        "                \n",
        "                # Store results\n",
        "                self.best_params[name] = grid_search.best_params_\n",
        "                self.classifiers[name]['trained_model'] = grid_search.best_estimator_\n",
        "                self.cv_scores[name] = grid_search.best_score_\n",
        "                \n",
        "                if verbose:\n",
        "                    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "                    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
        "            else:\n",
        "                # Train with default parameters\n",
        "                clf_info['model'].fit(X_train, y_train)\n",
        "                self.classifiers[name]['trained_model'] = clf_info['model']\n",
        "                self.best_params[name] = \"Default parameters\"\n",
        "                \n",
        "                if verbose:\n",
        "                    print(\"Using default parameters\")\n",
        "    \n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Evaluate all trained classifiers on test data.\n",
        "        \n",
        "        Returns:\n",
        "        --------\n",
        "        dict : Evaluation results for each classifier\n",
        "        \"\"\"\n",
        "        for name, clf_info in self.classifiers.items():\n",
        "            if 'trained_model' in clf_info:\n",
        "                y_pred = clf_info['trained_model'].predict(X_test)\n",
        "                \n",
        "                self.results[name] = {\n",
        "                    'accuracy': accuracy_score(y_test, y_pred),\n",
        "                    'precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "                    'sensitivity': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "                    'f1': f1_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "                    'predictions': y_pred\n",
        "                }\n",
        "        return self.results\n",
        "    \n",
        "    def get_trained_classifiers(self):\n",
        "        \"\"\"Return dictionary of trained classifier objects.\"\"\"\n",
        "        return {\n",
        "            name: info['trained_model'] \n",
        "            for name, info in self.classifiers.items() \n",
        "            if 'trained_model' in info\n",
        "        }\n",
        "    \n",
        "    def get_results_dataframe(self):\n",
        "        \"\"\"Return results as a pandas DataFrame.\"\"\"\n",
        "        return pd.DataFrame({\n",
        "            'Classifier': list(self.results.keys()),\n",
        "            'Accuracy': [self.results[k]['accuracy'] for k in self.results],\n",
        "            'Precision': [self.results[k]['precision'] for k in self.results],\n",
        "            'Sensitivity': [self.results[k]['sensitivity'] for k in self.results],\n",
        "            'F1-Score': [self.results[k]['f1'] for k in self.results]\n",
        "        })\n",
        "\n",
        "print(\"✓ ClassifierManager class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Define Base Classifiers with Parameter Grids\n",
        "\n",
        "Each classifier is defined with a search space for hyperparameter optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 1. MLP Neural Network\n",
        "# ============================================================\n",
        "# Multi-layer Perceptron with backpropagation\n",
        "# Key parameters:\n",
        "#   - hidden_layer_sizes: architecture of hidden layers\n",
        "#   - activation: activation function (relu, tanh)\n",
        "#   - alpha: L2 regularization term\n",
        "#   - learning_rate: learning rate schedule\n",
        "\n",
        "mlp_classifier = MLPClassifier(\n",
        "    max_iter=500,           # Maximum iterations\n",
        "    random_state=42,\n",
        "    early_stopping=True,    # Stop when validation score stops improving\n",
        "    validation_fraction=0.1\n",
        ")\n",
        "\n",
        "mlp_param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (128, 64)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "print(\"MLP Classifier defined\")\n",
        "print(f\"  Parameter combinations: {np.prod([len(v) for v in mlp_param_grid.values()])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 2. RBF Neural Network\n",
        "# ============================================================\n",
        "# Approximation of RBF network using:\n",
        "#   - RBFSampler: approximates RBF kernel feature map\n",
        "#   - SGDClassifier: linear classifier with SGD optimization\n",
        "#\n",
        "# This combination approximates an RBF network by:\n",
        "#   1. Transforming input features to RBF kernel space\n",
        "#   2. Training a linear classifier in that space\n",
        "\n",
        "rbf_classifier = Pipeline([\n",
        "    ('rbf_feature', RBFSampler(random_state=42)),\n",
        "    ('sgd', SGDClassifier(random_state=42, max_iter=1000, tol=1e-3))\n",
        "])\n",
        "\n",
        "rbf_param_grid = {\n",
        "    'rbf_feature__gamma': [0.01, 0.1, 1.0],      # RBF kernel width\n",
        "    'rbf_feature__n_components': [50, 100, 200],  # Number of RBF centers\n",
        "    'sgd__alpha': [0.0001, 0.001, 0.01]           # Regularization\n",
        "}\n",
        "\n",
        "print(\"RBF Classifier defined\")\n",
        "print(f\"  Parameter combinations: {np.prod([len(v) for v in rbf_param_grid.values()])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 3. k-Nearest Neighbors (k-NN)\n",
        "# ============================================================\n",
        "# Instance-based learning algorithm that classifies based on\n",
        "# the k closest training examples in feature space.\n",
        "#\n",
        "# Key parameters:\n",
        "#   - n_neighbors: number of neighbors to consider\n",
        "#   - weights: how to weight neighbor contributions\n",
        "#   - metric: distance measure\n",
        "\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "\n",
        "knn_param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "print(\"k-NN Classifier defined\")\n",
        "print(f\"  Parameter combinations: {np.prod([len(v) for v in knn_param_grid.values()])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 4. Gaussian Process Classifier\n",
        "# ============================================================\n",
        "# A probabilistic classifier that uses Gaussian process priors.\n",
        "# Note: GP classifiers are computationally expensive O(n³),\n",
        "# so we'll use a smaller subset for training.\n",
        "#\n",
        "# Key parameter:\n",
        "#   - kernel: defines similarity between points\n",
        "\n",
        "gp_classifier = GaussianProcessClassifier(\n",
        "    random_state=42,\n",
        "    max_iter_predict=100,\n",
        "    n_restarts_optimizer=0  # Reduce for speed\n",
        ")\n",
        "\n",
        "# Define different RBF kernel configurations\n",
        "gp_param_grid = {\n",
        "    'kernel': [\n",
        "        1.0 * RBF_Kernel(length_scale=0.5),\n",
        "        1.0 * RBF_Kernel(length_scale=1.0),\n",
        "        1.0 * RBF_Kernel(length_scale=2.0)\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"Gaussian Process Classifier defined\")\n",
        "print(\"  Note: Will use smaller subset due to O(n³) complexity\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 5. Gaussian Naive Bayes\n",
        "# ============================================================\n",
        "# Probabilistic classifier based on Bayes' theorem with\n",
        "# the \"naive\" assumption of feature independence.\n",
        "#\n",
        "# Key parameter:\n",
        "#   - var_smoothing: portion of largest variance added\n",
        "#     to variances for calculation stability\n",
        "\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "nb_param_grid = {\n",
        "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
        "}\n",
        "\n",
        "print(\"Naive Bayes Classifier defined\")\n",
        "print(f\"  Parameter combinations: {len(nb_param_grid['var_smoothing'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Train and Evaluate on Forest Covtype Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize classifier manager for Forest Covtype\n",
        "clf_manager_cov = ClassifierManager()\n",
        "\n",
        "# Add classifiers (except GP which needs special handling)\n",
        "clf_manager_cov.add_classifier('MLP', mlp_classifier, mlp_param_grid)\n",
        "clf_manager_cov.add_classifier('RBF', rbf_classifier, rbf_param_grid)\n",
        "clf_manager_cov.add_classifier('KNN', knn_classifier, knn_param_grid)\n",
        "clf_manager_cov.add_classifier('Naive Bayes', nb_classifier, nb_param_grid)\n",
        "\n",
        "print(\"Classifiers added to manager:\")\n",
        "for name in clf_manager_cov.classifiers:\n",
        "    print(f\"  - {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train classifiers on Forest Covtype (this may take several minutes)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING CLASSIFIERS ON FOREST COVTYPE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "clf_manager_cov.optimize_and_train(X_train_cov, y_train_cov, cv=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Gaussian Process separately with smaller sample\n",
        "# (GP is O(n³) complexity, so we use a subset)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training: Gaussian Process (with reduced sample)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "GP_SAMPLE_SIZE = 2000\n",
        "gp_indices = np.random.choice(len(X_train_cov), GP_SAMPLE_SIZE, replace=False)\n",
        "X_train_gp = X_train_cov[gp_indices]\n",
        "y_train_gp = y_train_cov[gp_indices]\n",
        "\n",
        "print(f\"Using {GP_SAMPLE_SIZE} samples for GP training\")\n",
        "\n",
        "# Train GP with best kernel from grid search on small subset\n",
        "best_gp_score = 0\n",
        "best_gp_kernel = None\n",
        "best_gp_model = None\n",
        "\n",
        "for kernel in gp_param_grid['kernel']:\n",
        "    gp = GaussianProcessClassifier(kernel=kernel, random_state=42, max_iter_predict=100)\n",
        "    gp.fit(X_train_gp, y_train_gp)\n",
        "    score = gp.score(X_train_gp, y_train_gp)\n",
        "    if score > best_gp_score:\n",
        "        best_gp_score = score\n",
        "        best_gp_kernel = kernel\n",
        "        best_gp_model = gp\n",
        "\n",
        "# Add GP to manager\n",
        "clf_manager_cov.classifiers['GP'] = {'trained_model': best_gp_model}\n",
        "clf_manager_cov.best_params['GP'] = {'kernel': str(best_gp_kernel), 'sample_size': GP_SAMPLE_SIZE}\n",
        "\n",
        "print(f\"Best kernel: {best_gp_kernel}\")\n",
        "print(f\"Training accuracy: {best_gp_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate all classifiers\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION RESULTS - FOREST COVTYPE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_cov = clf_manager_cov.evaluate(X_test_cov, y_test_cov)\n",
        "results_df_cov = clf_manager_cov.get_results_dataframe()\n",
        "\n",
        "# Sort by accuracy\n",
        "results_df_cov = results_df_cov.sort_values('Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\nBase Classifier Results:\")\n",
        "print(results_df_cov.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize results\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "metrics = ['Accuracy', 'Precision', 'Sensitivity']\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "\n",
        "for idx, (metric, color) in enumerate(zip(metrics, colors)):\n",
        "    ax = axes[idx]\n",
        "    bars = ax.bar(results_df_cov['Classifier'], results_df_cov[metric], \n",
        "                  color=color, alpha=0.8, edgecolor='black')\n",
        "    ax.set_title(f'{metric}', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.set_ylabel('Score')\n",
        "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.3f}',\n",
        "                    xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                    xytext=(0, 3), textcoords='offset points',\n",
        "                    ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.suptitle('Base Classifier Performance - Forest Covtype', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Display Optimal Parameters\n",
        "\n",
        "Summary of the best hyperparameters found for each classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"OPTIMAL PARAMETERS - FOREST COVTYPE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for name, params in clf_manager_cov.best_params.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    if isinstance(params, dict):\n",
        "        for param_name, value in params.items():\n",
        "            print(f\"  {param_name}: {value}\")\n",
        "    else:\n",
        "        print(f\"  {params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 4: Implementing Ensemble Classifier\n",
        "\n",
        "We combine the base classifiers using multiple ensemble strategies:\n",
        "\n",
        "1. **Hard Voting**: Each classifier votes for a class, majority wins\n",
        "2. **Soft Voting**: Average predicted probabilities across classifiers\n",
        "3. **Weighted Voting**: Like hard voting but with optimized weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Custom Ensemble Classifier Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomEnsembleClassifier:\n",
        "    \"\"\"\n",
        "    Custom ensemble classifier with multiple voting strategies:\n",
        "    - Hard Voting: Majority vote\n",
        "    - Soft Voting: Average probabilities\n",
        "    - Weighted Voting: Weighted majority vote\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    classifiers : dict\n",
        "        Dictionary of trained classifier objects {name: classifier}\n",
        "    voting : str\n",
        "        Voting strategy: 'hard', 'soft', or 'weighted'\n",
        "    weights : dict or None\n",
        "        Weights for each classifier (used in weighted voting)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, classifiers, voting='hard', weights=None):\n",
        "        self.classifiers = classifiers\n",
        "        self.voting = voting\n",
        "        self.weights = weights if weights else {name: 1.0 for name in classifiers}\n",
        "        self.classes_ = None\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions using the ensemble.\"\"\"\n",
        "        if self.voting == 'hard':\n",
        "            return self._hard_voting(X)\n",
        "        elif self.voting == 'weighted':\n",
        "            return self._weighted_voting(X)\n",
        "        elif self.voting == 'soft':\n",
        "            return self._soft_voting(X)\n",
        "    \n",
        "    def _hard_voting(self, X):\n",
        "        \"\"\"\n",
        "        Hard voting: Each classifier votes, class with most votes wins.\n",
        "        \"\"\"\n",
        "        predictions = np.array([clf.predict(X) for clf in self.classifiers.values()])\n",
        "        # Transpose to get predictions per sample\n",
        "        predictions = predictions.T\n",
        "        \n",
        "        final_pred = []\n",
        "        for row in predictions:\n",
        "            counter = Counter(row)\n",
        "            final_pred.append(counter.most_common(1)[0][0])\n",
        "        \n",
        "        return np.array(final_pred)\n",
        "    \n",
        "    def _weighted_voting(self, X):\n",
        "        \"\"\"\n",
        "        Weighted voting: Each classifier's vote is weighted.\n",
        "        \"\"\"\n",
        "        predictions = {name: clf.predict(X) for name, clf in self.classifiers.items()}\n",
        "        n_samples = len(list(predictions.values())[0])\n",
        "        \n",
        "        final_pred = []\n",
        "        for i in range(n_samples):\n",
        "            weighted_votes = {}\n",
        "            for name, preds in predictions.items():\n",
        "                pred = preds[i]\n",
        "                if pred not in weighted_votes:\n",
        "                    weighted_votes[pred] = 0\n",
        "                weighted_votes[pred] += self.weights[name]\n",
        "            \n",
        "            final_pred.append(max(weighted_votes, key=weighted_votes.get))\n",
        "        \n",
        "        return np.array(final_pred)\n",
        "    \n",
        "    def _soft_voting(self, X):\n",
        "        \"\"\"\n",
        "        Soft voting: Average predicted probabilities.\n",
        "        Falls back to hard voting if classifiers don't support predict_proba.\n",
        "        \"\"\"\n",
        "        probas = []\n",
        "        for name, clf in self.classifiers.items():\n",
        "            if hasattr(clf, 'predict_proba'):\n",
        "                try:\n",
        "                    proba = clf.predict_proba(X)\n",
        "                    probas.append(proba * self.weights[name])\n",
        "                except:\n",
        "                    pass\n",
        "        \n",
        "        if not probas:\n",
        "            return self._hard_voting(X)\n",
        "        \n",
        "        # Average probabilities\n",
        "        avg_proba = np.mean(probas, axis=0)\n",
        "        \n",
        "        # Get the classes from the first classifier that has them\n",
        "        for clf in self.classifiers.values():\n",
        "            if hasattr(clf, 'classes_'):\n",
        "                return clf.classes_[np.argmax(avg_proba, axis=1)]\n",
        "        \n",
        "        return np.argmax(avg_proba, axis=1)\n",
        "\n",
        "print(\"✓ CustomEnsembleClassifier class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Weight Optimization Function\n",
        "\n",
        "Optimize ensemble weights using random search with validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimize_ensemble_weights(classifiers, X_val, y_val, n_iterations=100, verbose=True):\n",
        "    \"\"\"\n",
        "    Optimize ensemble weights using random search.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    classifiers : dict\n",
        "        Dictionary of trained classifiers\n",
        "    X_val : array-like\n",
        "        Validation features\n",
        "    y_val : array-like\n",
        "        Validation labels\n",
        "    n_iterations : int\n",
        "        Number of random weight combinations to try\n",
        "    verbose : bool\n",
        "        Print progress\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    best_weights : dict\n",
        "        Optimal weights for each classifier\n",
        "    best_accuracy : float\n",
        "        Best validation accuracy achieved\n",
        "    \"\"\"\n",
        "    best_weights = None\n",
        "    best_accuracy = 0\n",
        "    clf_names = list(classifiers.keys())\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"Optimizing weights with {n_iterations} iterations...\")\n",
        "    \n",
        "    for i in range(n_iterations):\n",
        "        # Generate random weights using Dirichlet distribution\n",
        "        # This ensures weights sum to 1 and are all positive\n",
        "        random_weights = np.random.dirichlet(np.ones(len(clf_names)))\n",
        "        weights = {name: w for name, w in zip(clf_names, random_weights)}\n",
        "        \n",
        "        # Create ensemble with these weights\n",
        "        ensemble = CustomEnsembleClassifier(classifiers, voting='weighted', weights=weights)\n",
        "        \n",
        "        # Evaluate\n",
        "        y_pred = ensemble.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        \n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_weights = weights.copy()\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"Best validation accuracy: {best_accuracy:.4f}\")\n",
        "    \n",
        "    return best_weights, best_accuracy\n",
        "\n",
        "print(\"✓ Weight optimization function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Build and Evaluate Ensemble Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get trained classifiers\n",
        "trained_classifiers_cov = clf_manager_cov.get_trained_classifiers()\n",
        "\n",
        "print(\"Trained classifiers available for ensemble:\")\n",
        "for name in trained_classifiers_cov:\n",
        "    print(f\"  - {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split test set into validation and final test\n",
        "# Validation set is used for weight optimization\n",
        "val_size = int(len(X_test_cov) * 0.3)\n",
        "X_val_cov = X_test_cov[:val_size]\n",
        "y_val_cov = y_test_cov[:val_size]\n",
        "X_final_test_cov = X_test_cov[val_size:]\n",
        "y_final_test_cov = y_test_cov[val_size:]\n",
        "\n",
        "print(f\"Validation set size: {len(X_val_cov)}\")\n",
        "print(f\"Final test set size: {len(X_final_test_cov)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimize ensemble weights\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"OPTIMIZING ENSEMBLE WEIGHTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_weights_cov, val_accuracy = optimize_ensemble_weights(\n",
        "    trained_classifiers_cov, \n",
        "    X_val_cov, \n",
        "    y_val_cov, \n",
        "    n_iterations=100\n",
        ")\n",
        "\n",
        "print(\"\\nOptimal weights found:\")\n",
        "for name, weight in sorted(best_weights_cov.items(), key=lambda x: -x[1]):\n",
        "    print(f\"  {name}: {weight:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate different ensemble strategies\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ENSEMBLE CLASSIFIER EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "ensemble_results_cov = {}\n",
        "\n",
        "# 1. Hard Voting\n",
        "print(\"\\n1. Evaluating Hard Voting...\")\n",
        "ensemble_hard = CustomEnsembleClassifier(trained_classifiers_cov, voting='hard')\n",
        "y_pred_hard = ensemble_hard.predict(X_final_test_cov)\n",
        "ensemble_results_cov['Hard Voting'] = {\n",
        "    'accuracy': accuracy_score(y_final_test_cov, y_pred_hard),\n",
        "    'precision': precision_score(y_final_test_cov, y_pred_hard, average='weighted', zero_division=0),\n",
        "    'sensitivity': recall_score(y_final_test_cov, y_pred_hard, average='weighted', zero_division=0)\n",
        "}\n",
        "print(f\"   Accuracy: {ensemble_results_cov['Hard Voting']['accuracy']:.4f}\")\n",
        "\n",
        "# 2. Weighted Voting (with optimized weights)\n",
        "print(\"\\n2. Evaluating Weighted Voting (optimized)...\")\n",
        "ensemble_weighted = CustomEnsembleClassifier(\n",
        "    trained_classifiers_cov, voting='weighted', weights=best_weights_cov\n",
        ")\n",
        "y_pred_weighted = ensemble_weighted.predict(X_final_test_cov)\n",
        "ensemble_results_cov['Weighted Voting'] = {\n",
        "    'accuracy': accuracy_score(y_final_test_cov, y_pred_weighted),\n",
        "    'precision': precision_score(y_final_test_cov, y_pred_weighted, average='weighted', zero_division=0),\n",
        "    'sensitivity': recall_score(y_final_test_cov, y_pred_weighted, average='weighted', zero_division=0)\n",
        "}\n",
        "print(f\"   Accuracy: {ensemble_results_cov['Weighted Voting']['accuracy']:.4f}\")\n",
        "\n",
        "# 3. Soft Voting\n",
        "print(\"\\n3. Evaluating Soft Voting...\")\n",
        "ensemble_soft = CustomEnsembleClassifier(trained_classifiers_cov, voting='soft')\n",
        "y_pred_soft = ensemble_soft.predict(X_final_test_cov)\n",
        "ensemble_results_cov['Soft Voting'] = {\n",
        "    'accuracy': accuracy_score(y_final_test_cov, y_pred_soft),\n",
        "    'precision': precision_score(y_final_test_cov, y_pred_soft, average='weighted', zero_division=0),\n",
        "    'sensitivity': recall_score(y_final_test_cov, y_pred_soft, average='weighted', zero_division=0)\n",
        "}\n",
        "print(f\"   Accuracy: {ensemble_results_cov['Soft Voting']['accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison table: Base vs Ensemble\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARISON: BASE CLASSIFIERS vs ENSEMBLES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Re-evaluate base classifiers on final test set\n",
        "all_results_cov = {}\n",
        "\n",
        "for name, clf in trained_classifiers_cov.items():\n",
        "    y_pred = clf.predict(X_final_test_cov)\n",
        "    all_results_cov[f'{name} (Base)'] = {\n",
        "        'accuracy': accuracy_score(y_final_test_cov, y_pred),\n",
        "        'precision': precision_score(y_final_test_cov, y_pred, average='weighted', zero_division=0),\n",
        "        'sensitivity': recall_score(y_final_test_cov, y_pred, average='weighted', zero_division=0)\n",
        "    }\n",
        "\n",
        "# Add ensemble results\n",
        "for name, metrics in ensemble_results_cov.items():\n",
        "    all_results_cov[f'{name} (Ensemble)'] = metrics\n",
        "\n",
        "# Create DataFrame\n",
        "comparison_df_cov = pd.DataFrame({\n",
        "    'Model': list(all_results_cov.keys()),\n",
        "    'Accuracy': [all_results_cov[k]['accuracy'] for k in all_results_cov],\n",
        "    'Precision': [all_results_cov[k]['precision'] for k in all_results_cov],\n",
        "    'Sensitivity': [all_results_cov[k]['sensitivity'] for k in all_results_cov]\n",
        "}).sort_values('Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\n\" + comparison_df_cov.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization: Base vs Ensemble comparison\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "x = np.arange(len(comparison_df_cov))\n",
        "width = 0.25\n",
        "\n",
        "# Color based on whether it's base or ensemble\n",
        "colors_acc = ['#e74c3c' if 'Ensemble' in m else '#3498db' for m in comparison_df_cov['Model']]\n",
        "\n",
        "bars1 = ax.bar(x - width, comparison_df_cov['Accuracy'], width, label='Accuracy', color=colors_acc, alpha=0.8)\n",
        "bars2 = ax.bar(x, comparison_df_cov['Precision'], width, label='Precision', color='#2ecc71', alpha=0.7)\n",
        "bars3 = ax.bar(x + width, comparison_df_cov['Sensitivity'], width, label='Sensitivity', color='#f39c12', alpha=0.7)\n",
        "\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "ax.set_title('Base Classifiers vs Ensemble Methods - Forest Covtype', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(comparison_df_cov['Model'], rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.set_ylim(0, 1.15)\n",
        "\n",
        "# Add horizontal line at best single classifier\n",
        "best_base = comparison_df_cov[comparison_df_cov['Model'].str.contains('Base')]['Accuracy'].max()\n",
        "ax.axhline(y=best_base, color='red', linestyle='--', alpha=0.5, label='Best Base')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 5: Implementing Ensemble Clustering\n",
        "\n",
        "We implement three base clustering algorithms:\n",
        "- **k-Means**: Partitional clustering using centroid distance\n",
        "- **k-Medoids**: Like k-Means but uses actual data points as centers\n",
        "- **DIANA**: Divisive hierarchical clustering\n",
        "\n",
        "Then combine them using consensus clustering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Clustering Manager Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ClusteringManager:\n",
        "    \"\"\"\n",
        "    Manager class for clustering algorithms with:\n",
        "    - Automatic selection of optimal number of clusters\n",
        "    - Multiple clustering algorithm support\n",
        "    - Parameter tracking\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.clusterers = {}\n",
        "        self.labels = {}\n",
        "        self.best_params = {}\n",
        "    \n",
        "    def add_clusterer(self, name, clusterer_type):\n",
        "        \"\"\"\n",
        "        Add a clusterer by type.\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        name : str\n",
        "            Name identifier\n",
        "        clusterer_type : str\n",
        "            One of 'kmeans', 'kmedoids', 'diana'\n",
        "        \"\"\"\n",
        "        self.clusterers[name] = {'type': clusterer_type}\n",
        "    \n",
        "    def fit_predict(self, X, n_clusters_range=range(2, 11), verbose=True):\n",
        "        \"\"\"\n",
        "        Fit all clusterers and find optimal number of clusters using silhouette score.\n",
        "        \"\"\"\n",
        "        for name, clust_info in self.clusterers.items():\n",
        "            if verbose:\n",
        "                print(f\"\\n{'='*50}\")\n",
        "                print(f\"Running: {name}\")\n",
        "                print(f\"{'='*50}\")\n",
        "            \n",
        "            best_score = -1\n",
        "            best_k = 2\n",
        "            best_labels = None\n",
        "            \n",
        "            for k in n_clusters_range:\n",
        "                try:\n",
        "                    # Create appropriate clusterer\n",
        "                    if clust_info['type'] == 'kmeans':\n",
        "                        model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "                    elif clust_info['type'] == 'kmedoids':\n",
        "                        model = KMedoids(n_clusters=k, random_state=42)\n",
        "                    elif clust_info['type'] == 'diana':\n",
        "                        # DIANA-like behavior using divisive hierarchical clustering\n",
        "                        model = AgglomerativeClustering(\n",
        "                            n_clusters=k, \n",
        "                            linkage='complete'  # Complete linkage for divisive-like behavior\n",
        "                        )\n",
        "                    else:\n",
        "                        continue\n",
        "                    \n",
        "                    labels = model.fit_predict(X)\n",
        "                    \n",
        "                    # Calculate silhouette score\n",
        "                    if len(np.unique(labels)) > 1:\n",
        "                        score = silhouette_score(X, labels)\n",
        "                        if verbose:\n",
        "                            print(f\"  k={k}: Silhouette={score:.4f}\")\n",
        "                        \n",
        "                        if score > best_score:\n",
        "                            best_score = score\n",
        "                            best_k = k\n",
        "                            best_labels = labels\n",
        "                \n",
        "                except Exception as e:\n",
        "                    if verbose:\n",
        "                        print(f\"  k={k}: Error - {str(e)[:50]}\")\n",
        "                    continue\n",
        "            \n",
        "            self.labels[name] = best_labels\n",
        "            self.best_params[name] = {\n",
        "                'n_clusters': best_k, \n",
        "                'silhouette_score': best_score\n",
        "            }\n",
        "            \n",
        "            if verbose:\n",
        "                print(f\"\\n  Best k: {best_k}\")\n",
        "                print(f\"  Best Silhouette: {best_score:.4f}\")\n",
        "    \n",
        "    def get_labels(self):\n",
        "        \"\"\"Return dictionary of clustering labels.\"\"\"\n",
        "        return self.labels\n",
        "\n",
        "print(\"✓ ClusteringManager class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Ensemble Clustering Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EnsembleClustering:\n",
        "    \"\"\"\n",
        "    Ensemble clustering using consensus approaches:\n",
        "    - Co-association matrix based consensus\n",
        "    - Voting-based ensemble\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    labels_dict : dict\n",
        "        Dictionary of clustering labels from different algorithms\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, labels_dict):\n",
        "        self.labels_dict = labels_dict\n",
        "        self.n_samples = len(list(labels_dict.values())[0])\n",
        "    \n",
        "    def compute_co_association_matrix(self):\n",
        "        \"\"\"\n",
        "        Compute co-association matrix.\n",
        "        Entry (i,j) = proportion of clusterings where i and j are in same cluster.\n",
        "        \"\"\"\n",
        "        co_matrix = np.zeros((self.n_samples, self.n_samples))\n",
        "        \n",
        "        for name, labels in self.labels_dict.items():\n",
        "            for i in range(self.n_samples):\n",
        "                for j in range(i, self.n_samples):\n",
        "                    if labels[i] == labels[j]:\n",
        "                        co_matrix[i, j] += 1\n",
        "                        co_matrix[j, i] += 1\n",
        "        \n",
        "        # Normalize by number of clusterings\n",
        "        co_matrix /= len(self.labels_dict)\n",
        "        return co_matrix\n",
        "    \n",
        "    def consensus_clustering(self, n_clusters, method='hierarchical'):\n",
        "        \"\"\"\n",
        "        Generate consensus clustering from co-association matrix.\n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        n_clusters : int\n",
        "            Target number of clusters\n",
        "        method : str\n",
        "            'hierarchical' or 'spectral'\n",
        "            \n",
        "        Returns:\n",
        "        --------\n",
        "        labels : array\n",
        "            Consensus cluster labels\n",
        "        \"\"\"\n",
        "        co_matrix = self.compute_co_association_matrix()\n",
        "        \n",
        "        # Convert similarity to distance\n",
        "        distance_matrix = 1 - co_matrix\n",
        "        \n",
        "        if method == 'hierarchical':\n",
        "            clusterer = AgglomerativeClustering(\n",
        "                n_clusters=n_clusters,\n",
        "                metric='precomputed',\n",
        "                linkage='average'\n",
        "            )\n",
        "            return clusterer.fit_predict(distance_matrix)\n",
        "        \n",
        "        elif method == 'spectral':\n",
        "            from sklearn.cluster import SpectralClustering\n",
        "            clusterer = SpectralClustering(\n",
        "                n_clusters=n_clusters,\n",
        "                affinity='precomputed',\n",
        "                random_state=42\n",
        "            )\n",
        "            return clusterer.fit_predict(co_matrix)\n",
        "    \n",
        "    def voting_ensemble(self):\n",
        "        \"\"\"\n",
        "        Simple voting-based ensemble.\n",
        "        Note: This is approximate since cluster labels are arbitrary.\n",
        "        \"\"\"\n",
        "        labels_array = np.array(list(self.labels_dict.values())).T\n",
        "        final_labels = []\n",
        "        \n",
        "        for row in labels_array:\n",
        "            counter = Counter(row)\n",
        "            final_labels.append(counter.most_common(1)[0][0])\n",
        "        \n",
        "        return np.array(final_labels)\n",
        "\n",
        "print(\"✓ EnsembleClustering class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Clustering Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_clustering_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate clustering evaluation metrics.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_true : array-like\n",
        "        True class labels\n",
        "    y_pred : array-like\n",
        "        Predicted cluster labels\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Dictionary with Rand Index and F-measure\n",
        "    \"\"\"\n",
        "    # Adjusted Rand Index (corrected for chance)\n",
        "    rand_index = adjusted_rand_score(y_true, y_pred)\n",
        "    \n",
        "    # Calculate F-measure using contingency matrix\n",
        "    contingency = contingency_matrix(y_true, y_pred)\n",
        "    \n",
        "    n_samples = len(y_true)\n",
        "    n_classes = contingency.shape[0]\n",
        "    n_clusters = contingency.shape[1]\n",
        "    \n",
        "    # Compute precision and recall for each class-cluster pair\n",
        "    f_measures = []\n",
        "    \n",
        "    for i in range(n_classes):\n",
        "        class_total = contingency[i].sum()\n",
        "        if class_total == 0:\n",
        "            continue\n",
        "            \n",
        "        best_f = 0\n",
        "        for j in range(n_clusters):\n",
        "            cluster_total = contingency[:, j].sum()\n",
        "            if cluster_total == 0:\n",
        "                continue\n",
        "                \n",
        "            precision = contingency[i, j] / cluster_total\n",
        "            recall = contingency[i, j] / class_total\n",
        "            \n",
        "            if precision + recall > 0:\n",
        "                f = 2 * precision * recall / (precision + recall)\n",
        "                best_f = max(best_f, f)\n",
        "        \n",
        "        f_measures.append(best_f * class_total)\n",
        "    \n",
        "    f_measure = sum(f_measures) / n_samples if f_measures else 0\n",
        "    \n",
        "    return {\n",
        "        'Rand Index': rand_index,\n",
        "        'F-measure': f_measure\n",
        "    }\n",
        "\n",
        "print(\"✓ Clustering evaluation function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Run Clustering Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for clustering (using smaller sample for efficiency)\n",
        "CLUSTER_SAMPLE_SIZE = 5000\n",
        "\n",
        "cluster_indices = np.random.choice(len(X_train_cov), CLUSTER_SAMPLE_SIZE, replace=False)\n",
        "X_cluster = X_train_cov[cluster_indices]\n",
        "y_cluster_true = y_train_cov[cluster_indices]\n",
        "\n",
        "# Number of true classes for reference\n",
        "n_true_clusters = len(np.unique(y_cluster_true))\n",
        "\n",
        "print(f\"Clustering data shape: {X_cluster.shape}\")\n",
        "print(f\"Number of true classes: {n_true_clusters}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and run clustering manager\n",
        "cluster_manager = ClusteringManager()\n",
        "\n",
        "# Add clustering algorithms\n",
        "cluster_manager.add_clusterer('k-Means', 'kmeans')\n",
        "cluster_manager.add_clusterer('k-Medoids', 'kmedoids')\n",
        "cluster_manager.add_clusterer('DIANA', 'diana')\n",
        "\n",
        "# Find optimal parameters and cluster\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RUNNING BASE CLUSTERING ALGORITHMS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "cluster_manager.fit_predict(\n",
        "    X_cluster, \n",
        "    n_clusters_range=range(2, n_true_clusters + 3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display optimal parameters\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"OPTIMAL CLUSTERING PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for name, params in cluster_manager.best_params.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    for param, value in params.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"  {param}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {param}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ensemble clustering\n",
        "labels_dict = cluster_manager.get_labels()\n",
        "ensemble_cluster = EnsembleClustering(labels_dict)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENERATING ENSEMBLE CLUSTERINGS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Use the number of true clusters for ensemble\n",
        "n_ensemble_clusters = n_true_clusters\n",
        "\n",
        "print(f\"\\nTarget clusters for ensemble: {n_ensemble_clusters}\")\n",
        "\n",
        "# Hierarchical consensus\n",
        "print(\"\\n1. Hierarchical Consensus Clustering...\")\n",
        "ensemble_labels_hier = ensemble_cluster.consensus_clustering(\n",
        "    n_ensemble_clusters, method='hierarchical'\n",
        ")\n",
        "\n",
        "# Spectral consensus\n",
        "print(\"2. Spectral Consensus Clustering...\")\n",
        "ensemble_labels_spectral = ensemble_cluster.consensus_clustering(\n",
        "    n_ensemble_clusters, method='spectral'\n",
        ")\n",
        "\n",
        "# Voting ensemble\n",
        "print(\"3. Voting-based Ensemble...\")\n",
        "ensemble_labels_voting = ensemble_cluster.voting_ensemble()\n",
        "\n",
        "print(\"\\n✓ Ensemble clusterings generated\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.5 Evaluate Clustering Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate all clustering methods\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CLUSTERING EVALUATION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "clustering_results = {}\n",
        "\n",
        "# Base clusterers\n",
        "for name, labels in labels_dict.items():\n",
        "    metrics = calculate_clustering_metrics(y_cluster_true, labels)\n",
        "    clustering_results[f'{name} (Base)'] = metrics\n",
        "\n",
        "# Ensemble clusterers\n",
        "clustering_results['Hierarchical Consensus (Ensemble)'] = calculate_clustering_metrics(\n",
        "    y_cluster_true, ensemble_labels_hier\n",
        ")\n",
        "clustering_results['Spectral Consensus (Ensemble)'] = calculate_clustering_metrics(\n",
        "    y_cluster_true, ensemble_labels_spectral\n",
        ")\n",
        "clustering_results['Voting (Ensemble)'] = calculate_clustering_metrics(\n",
        "    y_cluster_true, ensemble_labels_voting\n",
        ")\n",
        "\n",
        "# Create DataFrame\n",
        "clustering_df = pd.DataFrame({\n",
        "    'Method': list(clustering_results.keys()),\n",
        "    'Rand Index': [clustering_results[k]['Rand Index'] for k in clustering_results],\n",
        "    'F-measure': [clustering_results[k]['F-measure'] for k in clustering_results]\n",
        "}).sort_values('Rand Index', ascending=False)\n",
        "\n",
        "print(\"\\n\" + clustering_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize clustering results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Colors: Blue for base, Red for ensemble\n",
        "colors = ['#e74c3c' if 'Ensemble' in m else '#3498db' for m in clustering_df['Method']]\n",
        "\n",
        "# Rand Index\n",
        "ax1 = axes[0]\n",
        "bars1 = ax1.barh(clustering_df['Method'], clustering_df['Rand Index'], color=colors, alpha=0.8)\n",
        "ax1.set_xlabel('Rand Index', fontsize=12)\n",
        "ax1.set_title('Adjusted Rand Index Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlim(-0.1, 1.0)\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars1, clustering_df['Rand Index']):\n",
        "    ax1.text(val + 0.02, bar.get_y() + bar.get_height()/2, \n",
        "             f'{val:.3f}', va='center', fontsize=10)\n",
        "\n",
        "# F-measure\n",
        "ax2 = axes[1]\n",
        "bars2 = ax2.barh(clustering_df['Method'], clustering_df['F-measure'], color=colors, alpha=0.8)\n",
        "ax2.set_xlabel('F-measure', fontsize=12)\n",
        "ax2.set_title('F-measure Comparison', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlim(0, 1.0)\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars2, clustering_df['F-measure']):\n",
        "    ax2.text(val + 0.02, bar.get_y() + bar.get_height()/2, \n",
        "             f'{val:.3f}', va='center', fontsize=10)\n",
        "\n",
        "# Legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='#3498db', label='Base Method'),\n",
        "    Patch(facecolor='#e74c3c', label='Ensemble Method')\n",
        "]\n",
        "fig.legend(handles=legend_elements, loc='upper center', ncol=2, bbox_to_anchor=(0.5, 1.02))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 6: Evaluation on RCV1 (Reuters) Dataset\n",
        "\n",
        "Now we apply the same methodology to the RCV1 text classification dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train classifiers on RCV1\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING CLASSIFIERS ON RCV1 (REUTERS)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "clf_manager_rcv = ClassifierManager()\n",
        "\n",
        "# Use simpler parameter grids for faster training\n",
        "clf_manager_rcv.add_classifier('MLP', \n",
        "    MLPClassifier(max_iter=300, random_state=42, early_stopping=True),\n",
        "    {'hidden_layer_sizes': [(50,), (100,)], 'alpha': [0.001, 0.01]}\n",
        ")\n",
        "\n",
        "clf_manager_rcv.add_classifier('RBF',\n",
        "    Pipeline([\n",
        "        ('rbf_feature', RBFSampler(random_state=42)),\n",
        "        ('sgd', SGDClassifier(random_state=42, max_iter=1000))\n",
        "    ]),\n",
        "    {'rbf_feature__gamma': [0.1, 1.0], 'rbf_feature__n_components': [50, 100]}\n",
        ")\n",
        "\n",
        "clf_manager_rcv.add_classifier('KNN', \n",
        "    KNeighborsClassifier(),\n",
        "    {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
        ")\n",
        "\n",
        "clf_manager_rcv.add_classifier('Naive Bayes', \n",
        "    GaussianNB(),\n",
        "    {'var_smoothing': [1e-9, 1e-7]}\n",
        ")\n",
        "\n",
        "# Train\n",
        "clf_manager_rcv.optimize_and_train(X_train_rcv, y_train_rcv, cv=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate base classifiers on RCV1\n",
        "results_rcv = clf_manager_rcv.evaluate(X_test_rcv, y_test_rcv)\n",
        "results_df_rcv = clf_manager_rcv.get_results_dataframe()\n",
        "\n",
        "print(\"\\nBase Classifier Results on RCV1:\")\n",
        "print(results_df_rcv.sort_values('Accuracy', ascending=False).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build ensemble for RCV1\n",
        "trained_classifiers_rcv = clf_manager_rcv.get_trained_classifiers()\n",
        "\n",
        "# Split test data\n",
        "val_size_rcv = int(len(X_test_rcv) * 0.3)\n",
        "X_val_rcv = X_test_rcv[:val_size_rcv]\n",
        "y_val_rcv = y_test_rcv[:val_size_rcv]\n",
        "X_final_test_rcv = X_test_rcv[val_size_rcv:]\n",
        "y_final_test_rcv = y_test_rcv[val_size_rcv:]\n",
        "\n",
        "# Optimize weights\n",
        "print(\"\\nOptimizing ensemble weights for RCV1...\")\n",
        "best_weights_rcv, _ = optimize_ensemble_weights(\n",
        "    trained_classifiers_rcv, X_val_rcv, y_val_rcv, n_iterations=50\n",
        ")\n",
        "\n",
        "print(\"\\nOptimal weights for RCV1:\")\n",
        "for name, weight in sorted(best_weights_rcv.items(), key=lambda x: -x[1]):\n",
        "    print(f\"  {name}: {weight:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate ensemble methods on RCV1\n",
        "ensemble_results_rcv = {}\n",
        "\n",
        "# Hard Voting\n",
        "ensemble_hard_rcv = CustomEnsembleClassifier(trained_classifiers_rcv, voting='hard')\n",
        "y_pred_hard_rcv = ensemble_hard_rcv.predict(X_final_test_rcv)\n",
        "ensemble_results_rcv['Hard Voting'] = {\n",
        "    'accuracy': accuracy_score(y_final_test_rcv, y_pred_hard_rcv),\n",
        "    'precision': precision_score(y_final_test_rcv, y_pred_hard_rcv, average='weighted', zero_division=0),\n",
        "    'sensitivity': recall_score(y_final_test_rcv, y_pred_hard_rcv, average='weighted', zero_division=0)\n",
        "}\n",
        "\n",
        "# Weighted Voting\n",
        "ensemble_weighted_rcv = CustomEnsembleClassifier(\n",
        "    trained_classifiers_rcv, voting='weighted', weights=best_weights_rcv\n",
        ")\n",
        "y_pred_weighted_rcv = ensemble_weighted_rcv.predict(X_final_test_rcv)\n",
        "ensemble_results_rcv['Weighted Voting'] = {\n",
        "    'accuracy': accuracy_score(y_final_test_rcv, y_pred_weighted_rcv),\n",
        "    'precision': precision_score(y_final_test_rcv, y_pred_weighted_rcv, average='weighted', zero_division=0),\n",
        "    'sensitivity': recall_score(y_final_test_rcv, y_pred_weighted_rcv, average='weighted', zero_division=0)\n",
        "}\n",
        "\n",
        "# Display results\n",
        "print(\"\\nEnsemble Classifier Results on RCV1:\")\n",
        "ensemble_df_rcv = pd.DataFrame({\n",
        "    'Method': list(ensemble_results_rcv.keys()),\n",
        "    'Accuracy': [ensemble_results_rcv[k]['accuracy'] for k in ensemble_results_rcv],\n",
        "    'Precision': [ensemble_results_rcv[k]['precision'] for k in ensemble_results_rcv],\n",
        "    'Sensitivity': [ensemble_results_rcv[k]['sensitivity'] for k in ensemble_results_rcv]\n",
        "})\n",
        "print(ensemble_df_rcv.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Part 7: Final Report and Summary\n",
        "\n",
        "Comprehensive summary of all results, optimal parameters, and conclusions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"                         FINAL PROJECT REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"1. OPTIMAL CLASSIFIER PARAMETERS - FOREST COVTYPE\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for name, params in clf_manager_cov.best_params.items():\n",
        "    print(f\"\\n  {name}:\")\n",
        "    if isinstance(params, dict):\n",
        "        for k, v in params.items():\n",
        "            print(f\"    - {k}: {v}\")\n",
        "    else:\n",
        "        print(f\"    - {params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"2. OPTIMAL ENSEMBLE WEIGHTS - FOREST COVTYPE\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for name, weight in sorted(best_weights_cov.items(), key=lambda x: -x[1]):\n",
        "    bar = \"█\" * int(weight * 30)\n",
        "    print(f\"  {name:15}: {weight:.4f} {bar}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"3. OPTIMAL CLUSTERING PARAMETERS\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for name, params in cluster_manager.best_params.items():\n",
        "    print(f\"\\n  {name}:\")\n",
        "    for k, v in params.items():\n",
        "        if isinstance(v, float):\n",
        "            print(f\"    - {k}: {v:.4f}\")\n",
        "        else:\n",
        "            print(f\"    - {k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"4. CLASSIFICATION RESULTS SUMMARY\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "print(\"\\n  Forest Covtype:\")\n",
        "print(\"  \" + \"-\"*50)\n",
        "print(comparison_df_cov.to_string(index=False))\n",
        "\n",
        "print(\"\\n\\n  RCV1 (Reuters):\")\n",
        "print(\"  \" + \"-\"*50)\n",
        "# Combine base and ensemble for RCV1\n",
        "all_results_rcv = {}\n",
        "for name, clf in trained_classifiers_rcv.items():\n",
        "    y_pred = clf.predict(X_final_test_rcv)\n",
        "    all_results_rcv[f'{name} (Base)'] = {\n",
        "        'accuracy': accuracy_score(y_final_test_rcv, y_pred),\n",
        "        'precision': precision_score(y_final_test_rcv, y_pred, average='weighted', zero_division=0),\n",
        "        'sensitivity': recall_score(y_final_test_rcv, y_pred, average='weighted', zero_division=0)\n",
        "    }\n",
        "for name, metrics in ensemble_results_rcv.items():\n",
        "    all_results_rcv[f'{name} (Ensemble)'] = metrics\n",
        "\n",
        "comparison_df_rcv = pd.DataFrame({\n",
        "    'Model': list(all_results_rcv.keys()),\n",
        "    'Accuracy': [all_results_rcv[k]['accuracy'] for k in all_results_rcv],\n",
        "    'Precision': [all_results_rcv[k]['precision'] for k in all_results_rcv],\n",
        "    'Sensitivity': [all_results_rcv[k]['sensitivity'] for k in all_results_rcv]\n",
        "}).sort_values('Accuracy', ascending=False)\n",
        "\n",
        "print(comparison_df_rcv.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"5. CLUSTERING RESULTS SUMMARY\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "print(clustering_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"                           CONCLUSIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Best classification model\n",
        "best_clf_cov = comparison_df_cov.iloc[0]\n",
        "best_clf_rcv = comparison_df_rcv.iloc[0]\n",
        "\n",
        "print(\"\\n  CLASSIFICATION:\")\n",
        "print(\"  \" + \"-\"*50)\n",
        "print(f\"\\n  Best Model (Forest Covtype): {best_clf_cov['Model']}\")\n",
        "print(f\"    - Accuracy:    {best_clf_cov['Accuracy']:.4f}\")\n",
        "print(f\"    - Precision:   {best_clf_cov['Precision']:.4f}\")\n",
        "print(f\"    - Sensitivity: {best_clf_cov['Sensitivity']:.4f}\")\n",
        "\n",
        "print(f\"\\n  Best Model (RCV1): {best_clf_rcv['Model']}\")\n",
        "print(f\"    - Accuracy:    {best_clf_rcv['Accuracy']:.4f}\")\n",
        "print(f\"    - Precision:   {best_clf_rcv['Precision']:.4f}\")\n",
        "print(f\"    - Sensitivity: {best_clf_rcv['Sensitivity']:.4f}\")\n",
        "\n",
        "# Best clustering model\n",
        "best_cluster = clustering_df.iloc[0]\n",
        "\n",
        "print(\"\\n  CLUSTERING:\")\n",
        "print(\"  \" + \"-\"*50)\n",
        "print(f\"\\n  Best Method: {best_cluster['Method']}\")\n",
        "print(f\"    - Rand Index: {best_cluster['Rand Index']:.4f}\")\n",
        "print(f\"    - F-measure:  {best_cluster['F-measure']:.4f}\")\n",
        "\n",
        "# Key findings\n",
        "print(\"\\n  KEY FINDINGS:\")\n",
        "print(\"  \" + \"-\"*50)\n",
        "print(\"\")\n",
        "print(\"  1. Ensemble methods generally improve upon individual base classifiers\")\n",
        "print(\"     by combining their diverse predictions.\")\n",
        "print(\"\")\n",
        "print(\"  2. Weighted voting with optimized weights often outperforms simple\")\n",
        "print(\"     hard voting by giving more weight to better-performing classifiers.\")\n",
        "print(\"\")\n",
        "print(\"  3. Consensus-based ensemble clustering provides more stable and robust\")\n",
        "print(\"     cluster assignments than individual algorithms.\")\n",
        "print(\"\")\n",
        "print(\"  4. The optimal number of clusters and classifier hyperparameters vary\")\n",
        "print(\"     significantly between datasets, highlighting the importance of\")\n",
        "print(\"     dataset-specific tuning.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"                         END OF REPORT\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create final summary visualization\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Classification comparison - Forest Covtype\n",
        "ax1 = fig.add_subplot(2, 2, 1)\n",
        "colors = ['#e74c3c' if 'Ensemble' in m else '#3498db' for m in comparison_df_cov['Model'][:6]]\n",
        "ax1.barh(comparison_df_cov['Model'][:6], comparison_df_cov['Accuracy'][:6], color=colors)\n",
        "ax1.set_xlabel('Accuracy')\n",
        "ax1.set_title('Classification - Forest Covtype', fontweight='bold')\n",
        "ax1.set_xlim(0, 1)\n",
        "\n",
        "# Classification comparison - RCV1\n",
        "ax2 = fig.add_subplot(2, 2, 2)\n",
        "colors = ['#e74c3c' if 'Ensemble' in m else '#3498db' for m in comparison_df_rcv['Model'][:6]]\n",
        "ax2.barh(comparison_df_rcv['Model'][:6], comparison_df_rcv['Accuracy'][:6], color=colors)\n",
        "ax2.set_xlabel('Accuracy')\n",
        "ax2.set_title('Classification - RCV1 (Reuters)', fontweight='bold')\n",
        "ax2.set_xlim(0, 1)\n",
        "\n",
        "# Clustering Rand Index\n",
        "ax3 = fig.add_subplot(2, 2, 3)\n",
        "colors = ['#e74c3c' if 'Ensemble' in m else '#3498db' for m in clustering_df['Method']]\n",
        "ax3.barh(clustering_df['Method'], clustering_df['Rand Index'], color=colors)\n",
        "ax3.set_xlabel('Rand Index')\n",
        "ax3.set_title('Clustering - Rand Index', fontweight='bold')\n",
        "ax3.set_xlim(-0.1, 1)\n",
        "\n",
        "# Clustering F-measure\n",
        "ax4 = fig.add_subplot(2, 2, 4)\n",
        "ax4.barh(clustering_df['Method'], clustering_df['F-measure'], color=colors)\n",
        "ax4.set_xlabel('F-measure')\n",
        "ax4.set_title('Clustering - F-measure', fontweight='bold')\n",
        "ax4.set_xlim(0, 1)\n",
        "\n",
        "# Add legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='#3498db', label='Base Method'),\n",
        "    Patch(facecolor='#e74c3c', label='Ensemble Method')\n",
        "]\n",
        "fig.legend(handles=legend_elements, loc='upper center', ncol=2, \n",
        "           bbox_to_anchor=(0.5, 1.02), fontsize=12)\n",
        "\n",
        "plt.suptitle('Hybrid Ensemble Learning - Complete Results Summary', \n",
        "             fontsize=16, fontweight='bold', y=1.05)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results to JSON for future reference\n",
        "import json\n",
        "\n",
        "def make_serializable(obj):\n",
        "    \"\"\"Convert numpy types to Python native types for JSON serialization.\"\"\"\n",
        "    if isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: make_serializable(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [make_serializable(i) for i in obj]\n",
        "    return obj\n",
        "\n",
        "# Compile final report\n",
        "final_report = {\n",
        "    'project': 'Hybrid Ensemble Learning',\n",
        "    'datasets': ['Forest Covtype', 'RCV1 (Reuters)'],\n",
        "    'classification': {\n",
        "        'base_methods': ['MLP', 'RBF', 'KNN', 'Gaussian Process', 'Naive Bayes'],\n",
        "        'ensemble_methods': ['Hard Voting', 'Weighted Voting', 'Soft Voting'],\n",
        "        'forest_covtype': {\n",
        "            'best_params': clf_manager_cov.best_params,\n",
        "            'ensemble_weights': best_weights_cov,\n",
        "            'results': all_results_cov\n",
        "        },\n",
        "        'rcv1': {\n",
        "            'best_params': clf_manager_rcv.best_params,\n",
        "            'ensemble_weights': best_weights_rcv,\n",
        "            'results': all_results_rcv\n",
        "        }\n",
        "    },\n",
        "    'clustering': {\n",
        "        'base_methods': ['k-Means', 'k-Medoids', 'DIANA'],\n",
        "        'ensemble_methods': ['Hierarchical Consensus', 'Spectral Consensus', 'Voting'],\n",
        "        'best_params': cluster_manager.best_params,\n",
        "        'results': clustering_results\n",
        "    }\n",
        "}\n",
        "\n",
        "# Make serializable\n",
        "serializable_report = make_serializable(final_report)\n",
        "\n",
        "print(\"\\nFinal report compiled successfully!\")\n",
        "print(\"\\nTo save the report to a JSON file, uncomment and run:\")\n",
        "print(\"# with open('ensemble_learning_report.json', 'w') as f:\")\n",
        "print(\"#     json.dump(serializable_report, f, indent=2)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "This notebook implemented a comprehensive hybrid ensemble learning system including:\n",
        "\n",
        "### Classification Ensemble:\n",
        "- **Base classifiers**: MLP, RBF, k-NN, Gaussian Process, Naive Bayes\n",
        "- **Ensemble methods**: Hard Voting, Soft Voting, Weighted Voting\n",
        "- **Parameter optimization**: GridSearchCV with cross-validation\n",
        "- **Weight optimization**: Random search with Dirichlet sampling\n",
        "\n",
        "### Clustering Ensemble:\n",
        "- **Base clusterers**: k-Means, k-Medoids, DIANA\n",
        "- **Ensemble methods**: Hierarchical Consensus, Spectral Consensus, Voting\n",
        "- **Parameter selection**: Silhouette score optimization\n",
        "\n",
        "### Evaluation Metrics:\n",
        "- **Classification**: Accuracy, Precision, Sensitivity (Recall)\n",
        "- **Clustering**: Adjusted Rand Index, F-measure\n",
        "\n",
        "### Key Observations:\n",
        "1. Ensemble methods generally provide more robust predictions than individual classifiers\n",
        "2. Weighted voting with optimized weights can outperform simple voting strategies\n",
        "3. Consensus clustering provides stable cluster assignments across multiple algorithms\n",
        "4. Dataset-specific hyperparameter tuning is crucial for optimal performance"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
